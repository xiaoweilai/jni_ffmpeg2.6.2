/* DO NOT EDIT THIS FILE - it is machine generated */
#include <string.h>
#include <jni.h>
#include <stdio.h>
#include <stdlib.h>


#include <libavcodec/avcodec.h>
#include <libavutil/channel_layout.h>
#include <libavutil/common.h>
#include <libavutil/imgutils.h>
#include <libavutil/mathematics.h>


#include "com_zhutieju_testservice_H264Android.h"
struct AVCodec *codec=NULL;			  // Codec
struct AVCodecContext *c=NULL;		  // Codec Context
struct AVFrame *picture=NULL;		  // Frame


#define INBUF_SIZE 4096
#define AUDIO_INBUF_SIZE 20480
#define AUDIO_REFILL_THRESH 4096


int iWidth=0;
int iHeight=0;

int *colortab=NULL;
int *u_b_tab=NULL;
int *u_g_tab=NULL;
int *v_g_tab=NULL;
int *v_r_tab=NULL;

//short *tmp_pic=NULL;

unsigned int *rgb_2_pix=NULL;
unsigned int *r_2_pix=NULL;
unsigned int *g_2_pix=NULL;
unsigned int *b_2_pix=NULL;






static int decode_write_frame(AVCodecContext *avctx, AVFrame *frame, int *frame_count, AVPacket *pkt, int last)
{
	int h;
	int w;
    int len, got_frame;
    char buf[1024];
    len = avcodec_decode_video2(avctx, frame, &got_frame, pkt);
    if (len < 0) {
        printf("Error while decoding frame %d\n", *frame_count);
        return len;
    }
    if (got_frame) {
        printf("Saving frame %3d\n", *frame_count);

//        QImage image(QSize(avctx->width, avctx->height), QImage::Format_RGB888);

        for(h = 0; h < avctx->height; h++)
        {
            for(w = 0; w < avctx->width; w ++)
            {
                int hh = h >> 1;
                int ww = w >> 1;
                int Y = frame->data[0][h * frame->linesize[0] + w];
                int U = frame->data[1][hh * (frame->linesize[1]) + ww];
                int V = frame->data[2][hh * (frame->linesize[2]) + ww];

                int C = Y - 16;
                int D = U - 128;
                int E = V - 128;

                int r = 298 * C           + 409 * E + 128;
                int g = 298 * C - 100 * D - 208 * E + 128;
                int b = 298 * C + 516 * D           + 128;

//                r = qBound(0, r >> 8, 255);
//                g = qBound(0, g >> 8, 255);
//                b = qBound(0, b >> 8, 255);
//
//                r = qBound(0, r, 255);
//                g = qBound(0, g, 255);
//                b = qBound(0, b, 255);

//                QRgb rgb = qRgb(r, g, b);
//                image.setPixel(QPoint(w, h), rgb);
            }
        }

//        QString fname = QString("img") + QString::number(*frame_count) + ".jpg";
//        image.save(fname);


        //pgm_save(frame->data[0], frame->linesize[0], avctx->width, avctx->height, buf);
        (*frame_count)++;
    }
    if (pkt->data) {
        pkt->size -= len;
        pkt->data += len;
    }
    return 0;
}




int mainloop(void)
{


    avcodec_register_all();
    AVCodec *codec;
    AVCodecContext *c= NULL;
    int frame_count;
    FILE *f;
    AVFrame *frame;
    uint8_t inbuf[INBUF_SIZE + FF_INPUT_BUFFER_PADDING_SIZE];
    AVPacket avpkt;
    av_init_packet(&avpkt);

    memset(inbuf + INBUF_SIZE, 0, FF_INPUT_BUFFER_PADDING_SIZE);


    codec = avcodec_find_decoder(AV_CODEC_ID_MPEG1VIDEO);
    if (!codec)
    {
        fprintf(stderr, "Codec not found\n");
        exit(1);
    }
    c = avcodec_alloc_context3(codec);
    if (!c) {
        fprintf(stderr, "Could not allocate video codec context\n");
        exit(1);
    }
    if(codec->capabilities&CODEC_CAP_TRUNCATED)
        c->flags|= CODEC_FLAG_TRUNCATED;
    if (avcodec_open2(c, codec, NULL) < 0) {
        fprintf(stderr, "Could not open codec\n");
        exit(1);
    }
    f = fopen("test.mpg", "rb");
    if (!f) {
        fprintf(stderr, "Could not open input file\n");
        exit(1);
    }
    frame = av_frame_alloc();
    if (!frame) {
        fprintf(stderr, "Could not allocate video frame\n");
        exit(1);
    }
    frame_count = 0;
    for (;;) {
        avpkt.size = fread(inbuf, 1, INBUF_SIZE, f);
        if (avpkt.size == 0)
            break;
        avpkt.data = inbuf;
        while (avpkt.size > 0)
            if (decode_write_frame(c, frame, &frame_count, &avpkt, 0) < 0)
                exit(1);
    }
}




static int init_codec()
{
	 avcodec_register_all();
	 AVCodec *codec;
	 AVCodecContext *c= NULL;
	 int frame_count;
	 FILE *f;
	 AVFrame *frame;
	 uint8_t inbuf[INBUF_SIZE + FF_INPUT_BUFFER_PADDING_SIZE];
	 AVPacket avpkt;
	 av_init_packet(&avpkt);
}




void DeleteYUVTab()
{
//	av_free(tmp_pic);

	av_free(colortab);
	av_free(rgb_2_pix);
}


void CreateYUVTab_16()
{
	int i;
	int u, v;

//	tmp_pic = (short*)av_malloc(iWidth*iHeight*2); // 缓存 iWidth * iHeight * 16bits

	colortab = (int *)av_malloc(4*256*sizeof(int));
	u_b_tab = &colortab[0*256];
	u_g_tab = &colortab[1*256];
	v_g_tab = &colortab[2*256];
	v_r_tab = &colortab[3*256];

	for (i=0; i<256; i++)
	{
		u = v = (i-128);

		u_b_tab[i] = (int) ( 1.772 * u);
		u_g_tab[i] = (int) ( 0.34414 * u);
		v_g_tab[i] = (int) ( 0.71414 * v);
		v_r_tab[i] = (int) ( 1.402 * v);
	}

	rgb_2_pix = (unsigned int *)av_malloc(3*768*sizeof(unsigned int));

	r_2_pix = &rgb_2_pix[0*768];
	g_2_pix = &rgb_2_pix[1*768];
	b_2_pix = &rgb_2_pix[2*768];

	for(i=0; i<256; i++)
	{
		r_2_pix[i] = 0;
		g_2_pix[i] = 0;
		b_2_pix[i] = 0;
	}

	for(i=0; i<256; i++)
	{
		r_2_pix[i+256] = (i & 0xF8) << 8;
		g_2_pix[i+256] = (i & 0xFC) << 3;
		b_2_pix[i+256] = (i ) >> 3;
	}

	for(i=0; i<256; i++)
	{
		r_2_pix[i+512] = 0xF8 << 8;
		g_2_pix[i+512] = 0xFC << 3;
		b_2_pix[i+512] = 0x1F;
	}

	r_2_pix += 256;
	g_2_pix += 256;
	b_2_pix += 256;
}

void DisplayYUV_16(unsigned int *pdst1, unsigned char *y, unsigned char *u, unsigned char *v, int width, int height, int src_ystride, int src_uvstride, int dst_ystride)
{
	int i, j;
	int r, g, b, rgb;

	int yy, ub, ug, vg, vr;

	unsigned char* yoff;
	unsigned char* uoff;
	unsigned char* voff;

	unsigned int* pdst=pdst1;

	int width2 = width/2;
	int height2 = height/2;

	if(width2>iWidth/2)
	{
		width2=iWidth/2;

		y+=(width-iWidth)/4*2;
		u+=(width-iWidth)/4;
		v+=(width-iWidth)/4;
	}

	if(height2>iHeight)
		height2=iHeight;

	for(j=0; j<height2; j++) // 一次2x2共四个像素
	{
		yoff = y + j * 2 * src_ystride;
		uoff = u + j * src_uvstride;
		voff = v + j * src_uvstride;

		for(i=0; i<width2; i++)
		{
			yy  = *(yoff+(i<<1));
			ub = u_b_tab[*(uoff+i)];
			ug = u_g_tab[*(uoff+i)];
			vg = v_g_tab[*(voff+i)];
			vr = v_r_tab[*(voff+i)];

			b = yy + ub;
			g = yy - ug - vg;
			r = yy + vr;

			rgb = r_2_pix[r] + g_2_pix[g] + b_2_pix[b];

			yy = *(yoff+(i<<1)+1);
			b = yy + ub;
			g = yy - ug - vg;
			r = yy + vr;

			pdst[(j*dst_ystride+i)] = (rgb)+((r_2_pix[r] + g_2_pix[g] + b_2_pix[b])<<16);

			yy = *(yoff+(i<<1)+src_ystride);
			b = yy + ub;
			g = yy - ug - vg;
			r = yy + vr;

			rgb = r_2_pix[r] + g_2_pix[g] + b_2_pix[b];

			yy = *(yoff+(i<<1)+src_ystride+1);
			b = yy + ub;
			g = yy - ug - vg;
			r = yy + vr;

			pdst [((2*j+1)*dst_ystride+i*2)>>1] = (rgb)+((r_2_pix[r] + g_2_pix[g] + b_2_pix[b])<<16);
		}
	}
}

/*
 * Class:     com_zhutieju_testservice_H264Android
 * Method:    initDecoder
 * Signature: (II)I
 */
JNIEXPORT jint JNICALL Java_com_zhutieju_testservice_H264Android_initDecoder
  (JNIEnv* env, jobject thiz, jint width, jint height)
{
	iWidth = width;
	iHeight = height;

	CreateYUVTab_16();
	
	//avcodec_init();

	avcodec_register_all();
	//找到H264解码器
	codec = avcodec_find_decoder(AV_CODEC_ID_H264);
	//分配解码器内存
	c = avcodec_alloc_context3(codec);
	//打开解码器
	avcodec_open2(c, codec, NULL);
	//给解码器解码后的帧数据分配存储空间
	picture  = av_frame_alloc();//picture= malloc(sizeof(AVFrame));

	return 1;
}

/*
 * Class:     com_zhutieju_testservice_H264Android
 * Method:    dalDecoder
 * Signature: ([BI[B)I
 */
JNIEXPORT jint JNICALL Java_com_zhutieju_testservice_H264Android_dalDecoder
  (JNIEnv* env, jobject thiz, jbyteArray in, jint nalLen, jbyteArray out)
{
	int i;
	int imod;
	int got_picture=0;

	jbyte * Buf = (jbyte*)(*env)->GetByteArrayElements(env, in, 0);
	jbyte * Pixel= (jbyte*)(*env)->GetByteArrayElements(env, out, 0);

	int consumed_bytes = avcodec_decode_video2(c, picture, &got_picture, Buf);

	if(got_picture > 0)
	{
		DisplayYUV_16((int*)Pixel, picture->data[0], picture->data[1], picture->data[2], c->width, c->height, picture->linesize[0], picture->linesize[1], iWidth);
/*
		for(i=0; i<c->height; i++)
			fwrite(picture->data[0] + i * picture->linesize[0], 1, c->width, outf);

		for(i=0; i<c->height/2; i++)
			fwrite(picture->data[1] + i * picture->linesize[1], 1, c->width/2, outf);

		for(i=0; i<c->height/2; i++)
			fwrite(picture->data[2] + i * picture->linesize[2], 1, c->width/2, outf);
// */
	}

    (*env)->ReleaseByteArrayElements(env, in, Buf, 0);
    (*env)->ReleaseByteArrayElements(env, out, Pixel, 0);

	return consumed_bytes;
}

/*
 * Class:     com_zhutieju_testservice_H264Android
 * Method:    releaseDecoder
 * Signature: ()I
 */
JNIEXPORT jint JNICALL Java_com_zhutieju_testservice_H264Android_releaseDecoder
  (JNIEnv* env, jobject thiz)
{
	if(c)
	{
		avcodec_close(c);
	    free(c->priv_data);

		free(c);
		c = NULL;
	}

	if(picture)
	{
		free(picture);
		picture = NULL;
	}

	DeleteYUVTab();

	return 1;
}
